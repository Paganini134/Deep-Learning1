{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GYte8f3RlUM9"},"outputs":[],"source":["# Color channels first representation of tensor data\n","#(batch_size, color_channels, height, width)\n","#Learn about CNNs\n","#One of the Architecture of a CNN (tHEY CAN BE STACKED TOGETHER IN many other ways :)\n","#Torch vision - Base domain library\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5948,"status":"ok","timestamp":1705321108311,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"oODvT5LYeIY9"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","import torchvision\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","#To look for- How do you fix the data to the pretrained model(used for CNNs)\n","#Fashion mnist dataset- Grayscale value of pieces of clothing\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7624,"status":"ok","timestamp":1705321115933,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"aQ0ZFFJgfGDl","outputId":"5914c58f-e613-4b52-bef1-292c12fbd67e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:02\u003c00:00, 10528846.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00\u003c00:00, 202323.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4422102/4422102 [00:01\u003c00:00, 3738564.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00\u003c00:00, 19955893.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Setup training data\n","train_data = datasets.FashionMNIST(\n","    root=\"data\", # where to download data to?\n","    train=True, # get training data\n","    download=True, # download data if it doesn't exist on disk\n","    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n","    target_transform=None # you can transform labels as well\n",")\n","\n","# Setup testing data\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False, # get test data\n","    download=True,\n","    transform=ToTensor()\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":463,"status":"ok","timestamp":1705321127711,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"gbvQi4kbj86-"},"outputs":[],"source":["image,label=train_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705246181425,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"Uk4RiTIIj89-","outputId":"e5a782c7-de6b-4418-a616-74cfa20cb561"},"outputs":[{"data":{"text/plain":["9"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["label"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705321115933,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"xDLR8wimj9Cr"},"outputs":[],"source":["dict_class=test_data.class_to_idx\n","#targets are the labels(y)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705321128183,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"GmJ8DxYMj9Fn"},"outputs":[{"ename":"TypeError","evalue":"'int' object is not subscriptable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-100-8b60d2c00dbf\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#(Color channel,height,width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"]}],"source":["(image).size() #(Color channel,height,width)"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1705322780153,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"okX8YbE9j9Ip","outputId":"1761ba6a-2f83-4fd2-9410-e7b896be36de"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cbuilt-in method squeeze of Tensor object at 0x79ac9d1acea0\u003e\n"]}],"source":["d=torch.arange(1,13)\n","x=d.reshape(2,6)\n","#View (or reshape)of a tensor shared the original memory as the initial tens\n","#d[0]=2\n","#torch.stack(dim tells you if it s horizontal or verical stack) takes a list of tensors\n","d,x\n","new=torch.zeros(2,1,2,1,2)\n","#plt.imshow(image)\n","print(new.squeeze)"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705322754459,"user":{"displayName":"SAKSHAM GUPTA","userId":"06110219496626753138"},"user_tz":-330},"id":"B_Kx3zvcj9Lx"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMxKZYPCZo0WdUL5kN4cMmG","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}